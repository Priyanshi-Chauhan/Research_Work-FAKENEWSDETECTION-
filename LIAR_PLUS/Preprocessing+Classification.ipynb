{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"complete_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>party_affiliation</th>\n",
       "      <th>barely_true_counts</th>\n",
       "      <th>false_counts</th>\n",
       "      <th>half_true_counts</th>\n",
       "      <th>mostly_true_counts</th>\n",
       "      <th>pants_on_fire_counts</th>\n",
       "      <th>context</th>\n",
       "      <th>extracted_justification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12787</th>\n",
       "      <td>half-true</td>\n",
       "      <td>For the first time in more than a decade, impo...</td>\n",
       "      <td>energy,oil-spill,trade</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>a press conference</td>\n",
       "      <td>In 2009, 17 percent of the U. S. 's oil import...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12788</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Says Donald Trump has bankrupted his companies...</td>\n",
       "      <td>candidates-biography</td>\n",
       "      <td>hillary-clinton</td>\n",
       "      <td>democrat</td>\n",
       "      <td>40.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>a speech on the economy</td>\n",
       "      <td>Clinton said, Trump has \"bankrupted his compan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12789</th>\n",
       "      <td>true</td>\n",
       "      <td>John McCain and George Bush have \"absolutely n...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>campaign-defend-america</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a television ad</td>\n",
       "      <td>\"I don't think that there should be a mandate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12790</th>\n",
       "      <td>false</td>\n",
       "      <td>A new poll shows 62 percent support the presid...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>americans-united-change</td>\n",
       "      <td>none</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>an Internet ad.</td>\n",
       "      <td>But the poll doesn't say that. Several days af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12791</th>\n",
       "      <td>barely-true</td>\n",
       "      <td>No one claims the report vindicating New Jerse...</td>\n",
       "      <td>candidates-biography,infrastructure</td>\n",
       "      <td>rudy-giuliani</td>\n",
       "      <td>republican</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>comments on NBC's \"Meet the Press\"</td>\n",
       "      <td>Giuliani said \"no one\" called the Mastro repor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             label                                          statement  \\\n",
       "12787    half-true  For the first time in more than a decade, impo...   \n",
       "12788  mostly-true  Says Donald Trump has bankrupted his companies...   \n",
       "12789         true  John McCain and George Bush have \"absolutely n...   \n",
       "12790        false  A new poll shows 62 percent support the presid...   \n",
       "12791  barely-true  No one claims the report vindicating New Jerse...   \n",
       "\n",
       "                                   subject                  speaker  \\\n",
       "12787               energy,oil-spill,trade             barack-obama   \n",
       "12788                 candidates-biography          hillary-clinton   \n",
       "12789                          health-care  campaign-defend-america   \n",
       "12790                          health-care  americans-united-change   \n",
       "12791  candidates-biography,infrastructure            rudy-giuliani   \n",
       "\n",
       "      party_affiliation  barely_true_counts  false_counts  half_true_counts  \\\n",
       "12787          democrat                70.0          71.0             160.0   \n",
       "12788          democrat                40.0          29.0              69.0   \n",
       "12789              none                 0.0           1.0               0.0   \n",
       "12790              none                 1.0           4.0               4.0   \n",
       "12791        republican                 9.0          11.0              10.0   \n",
       "\n",
       "       mostly_true_counts  pants_on_fire_counts  \\\n",
       "12787               163.0                   9.0   \n",
       "12788                76.0                   7.0   \n",
       "12789                 2.0                   0.0   \n",
       "12790                 1.0                   0.0   \n",
       "12791                 7.0                   3.0   \n",
       "\n",
       "                                  context  \\\n",
       "12787                  a press conference   \n",
       "12788             a speech on the economy   \n",
       "12789                     a television ad   \n",
       "12790                     an Internet ad.   \n",
       "12791  comments on NBC's \"Meet the Press\"   \n",
       "\n",
       "                                 extracted_justification  \n",
       "12787  In 2009, 17 percent of the U. S. 's oil import...  \n",
       "12788  Clinton said, Trump has \"bankrupted his compan...  \n",
       "12789  \"I don't think that there should be a mandate ...  \n",
       "12790  But the poll doesn't say that. Several days af...  \n",
       "12791  Giuliani said \"no one\" called the Mastro repor...  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12792, 12)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dropna(subset = [\"statement\",\"extracted_justification\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12691, 12)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12691 entries, 0 to 12791\n",
      "Data columns (total 12 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   label                    12691 non-null  object \n",
      " 1   statement                12691 non-null  object \n",
      " 2   subject                  12691 non-null  object \n",
      " 3   speaker                  12691 non-null  object \n",
      " 4   party_affiliation        12691 non-null  object \n",
      " 5   barely_true_counts       12691 non-null  float64\n",
      " 6   false_counts             12691 non-null  float64\n",
      " 7   half_true_counts         12691 non-null  float64\n",
      " 8   mostly_true_counts       12691 non-null  float64\n",
      " 9   pants_on_fire_counts     12691 non-null  float64\n",
      " 10  context                  12564 non-null  object \n",
      " 11  extracted_justification  12691 non-null  object \n",
      "dtypes: float64(5), object(7)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data=df_train[\"statement\"]+df_train[\"extracted_justification\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "punctuation = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "print(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "english_stopwords = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "ps=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords=set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Cleaning Functions\n",
    "def remove_punc(row):\n",
    "    tokenizer=RegexpTokenizer('[a-zA-Z]+')\n",
    "    tokens=tokenizer.tokenize(row)\n",
    "    row=row.lower()\n",
    "    tokens=row.split() \n",
    "    new_tokens=[w for w in tokens if w not in punctuation]\n",
    "    return new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data=X_data.apply(remove_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [when, did, the, decline, of, coal, start?, it...\n",
       "1        [hillary, clinton, agrees, with, john, mccain,...\n",
       "2        [health, care, reform, legislation, is, likely...\n",
       "3        [the, economic, turnaround, started, at, the, ...\n",
       "4        [the, chicago, bears, have, had, more, startin...\n",
       "                               ...                        \n",
       "12787    [for, the, first, time, in, more, than, a, dec...\n",
       "12788    [says, donald, trump, has, bankrupted, his, co...\n",
       "12789    [john, mccain, and, george, bush, have, \"absol...\n",
       "12790    [a, new, poll, shows, 62, percent, support, th...\n",
       "12791    [no, one, claims, the, report, vindicating, ne...\n",
       "Length: 12691, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_words={'com','http','www','stori','wa','hi','ha','pleas'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_stopwords=english_stopwords.union(additional_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc(row):\n",
    "    text = [ps.stem(word) for word in row]\n",
    "    text = [w for w in text if w not in total_stopwords]\n",
    "    text = [w.encode('ascii', 'ignore').decode('ascii') for w in text]\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rejoin(ro):\n",
    "    joined_text=(\" \".join(ro))\n",
    "    return joined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data=X_data.apply(proc)\n",
    "X_data=X_data.apply(rejoin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        declin coal start? start natur ga took start b...\n",
       "1        hillari clinton agre john mccain \"bi vote give...\n",
       "2        health care reform legisl like mandat free sex...\n",
       "3        econom turnaround start end term.crist said ec...\n",
       "4        chicago bear start quarterback last 10 year to...\n",
       "                               ...                        \n",
       "12787    first time decade, import account less half (t...\n",
       "12788    say donald trump bankrupt compani once, twice ...\n",
       "12789    john mccain georg bush \"absolut plan univers h...\n",
       "12790    new poll show 62 percent support president' pl...\n",
       "12791    one claim report vindic new jersey gov. chri c...\n",
       "Length: 12691, dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=df_train.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          half-true\n",
       "1        mostly-true\n",
       "2              false\n",
       "3          half-true\n",
       "4               true\n",
       "            ...     \n",
       "12787      half-true\n",
       "12788    mostly-true\n",
       "12789           true\n",
       "12790          false\n",
       "12791    barely-true\n",
       "Name: label, Length: 12691, dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=le.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 1, ..., 5, 1, 0])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0 in Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "print('Indexing word vectors.')\n",
    "\n",
    "embeddings_index = {}\n",
    "with open('glove.6B.50d.txt',encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25876 unique tokens in Train.\n",
      "Shape of Train data tensor: (12691, 64)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=10000,char_level=False)\n",
    "tokenizer.fit_on_texts(X_data)\n",
    "sequences_train = tokenizer.texts_to_sequences(X_data)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens in Train.' % len(word_index))\n",
    "data_train1 = pad_sequences(sequences_train, maxlen=64)\n",
    "print('Shape of Train data tensor:', data_train1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12691\n"
     ]
    }
   ],
   "source": [
    "print(len(sequences_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  46,  694,  322, ..., 1196,  507, 3831],\n",
       "       [   0,    0,    0, ...,  230,  712,  111],\n",
       "       [  66,  380,  110, ...,  239, 2487,   96],\n",
       "       ...,\n",
       "       [   0,    0,    0, ..., 1441, 3042, 6728],\n",
       "       [   0,    0,    0, ...,   18,   80,  874],\n",
       "       [   0,    0,    0, ...,  917,  275,   47]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUM_WORDS=10000\n",
    "MAX_SEQUENCE_LENGTH=64\n",
    "## More code adapted from the keras reference (https://github.com/keras-team/keras/blob/master/examples/pretrained_word_embeddings.py)\n",
    "# prepare embedding matrix \n",
    "from keras.layers import Embedding\n",
    "from keras.initializers import Constant\n",
    "\n",
    "## EMBEDDING_DIM =  ## seems to need to match the embeddings_index dimension\n",
    "EMBEDDING_DIM = embeddings_index.get('a').shape[0]\n",
    "num_words = min(MAX_NUM_WORDS, len(word_index)) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i > MAX_NUM_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word) ## This references the loaded embeddings dictionary\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# load pre-trained word embeddings into an Embedding layer\n",
    "# note that we set trainable = False so as to keep the embeddings fixed\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding_matrix = np.zeros((len(word_index) + 1, 50))\n",
    "#for word, i in word_index.items():\n",
    "#    embedding_vector = embeddings_index.get(word)\n",
    "#    if embedding_vector is not None:\n",
    "#        words not found in embedding index will be all-zeros.\n",
    "#        embedding_matrix[i] = (embedding_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding_matrix[8048898]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_output(data):\n",
    "    emb_dim=50\n",
    "    max_len=64\n",
    "    emb=np.zeros((data.shape[0],max_len,emb_dim))\n",
    "    print(emb.shape)\n",
    "    for i in range(data.shape[0]):\n",
    "        \n",
    "        for j in range(64):\n",
    "            try:\n",
    "                emb[i][j]=embeddings_index[data[i][j].lower()]\n",
    "            except:\n",
    "                emb[i][j]=np.zeros((50,))\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12691, 64, 50)\n"
     ]
    }
   ],
   "source": [
    "e=embedding_output(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=np.array(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "Y=le.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12691, 6)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "labels = to_categorical(np.asarray(Y))\n",
    "\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code from: https://medium.com/@sabber/classifying-yelp-review-comments-using-cnn-lstm-and-pre-trained-glove-word-embeddings-part-3-53fcea9a17fa\n",
    "## To create and visualize a model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(64,input_shape=(64,50),return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64,input_shape=(64,50),return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(6, activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hist=model.fit(e,labels,epochs=50,batch_size=64,shuffle=True,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATING A MODEL IN KERAS\n",
    "from keras.layers import Embedding,Dense,SimpleRNN\n",
    "from keras.models import Sequential\n",
    "model=Sequential()\n",
    "model.add(Embedding(10000,64))      # 10000 is the vocab_size and 64 is the output dimension i.e. k==embedding size\n",
    "model.add(SimpleRNN(64))           # 32  is the shape of context vector/ activation vector\n",
    "model.add(Dense(6,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compile our model \n",
    "model.compile(optimizer=\"Adam\",loss=\"binary_crossentropy\",metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12691/12691 [==============================] - 3s 272us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7099638139137318, 0.46393775939941406]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(data_train1,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.layers import Layer\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(attention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        self.W=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")        \n",
    "        super(attention, self).build(input_shape)\n",
    "\n",
    "    def call(self,x):\n",
    "        et=K.squeeze(K.tanh(K.dot(x,self.W)+self.b),axis=-1)\n",
    "        at=K.softmax(et)\n",
    "        at=K.expand_dims(at,axis=-1)\n",
    "        output=x*at\n",
    "        return K.sum(output,axis=1)\n",
    "\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return (input_shape[0],input_shape[-1])\n",
    "\n",
    "    def get_config(self):\n",
    "        return super(attention,self).get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import newaxis\n",
    "from keras.layers import Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def axis(a):\n",
    "    a = a[ :, :, newaxis]\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector_matrix = np.zeros((40000, 50))\n",
    "unavailable = 0\n",
    "\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    vector = embeddings_index.get(word)\n",
    "    if vector is not None:\n",
    "        word_vector_matrix[index] = vector\n",
    "    else:\n",
    "        unavailable = unavailable + 1\n",
    "        #print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "sequence_input = keras.layers.Input(shape=(64,), dtype='int32')\n",
    "x = keras.layers.Embedding(40000, 50, input_length = 64, weights = [word_vector_matrix], trainable = False)(sequence_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_out=attention()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Lambda(axis)(att_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = keras.layers.Conv1D(96,(11),strides = 2,activation = 'relu',input_shape=(100,1))(x)\n",
    "y = keras.layers.MaxPooling1D(3,2)(y)\n",
    "\n",
    "y = keras.layers.Conv1D(256,5,padding = 'same',activation = 'relu')(y)\n",
    "y = keras.layers.MaxPooling1D(3,2)(y)\n",
    "\n",
    "y = keras.layers.Conv1D(384,3,padding='same',activation= 'relu')(y)\n",
    "y = keras.layers.Conv1D(384,3,padding='same',activation= 'relu')(y)\n",
    "y = keras.layers.Conv1D(256,3,padding='same',activation= 'relu')(y)\n",
    "y = keras.layers.MaxPooling1D(3,2)(y)\n",
    "\n",
    "y = keras.layers.Flatten()(y)\n",
    "y = keras.layers.Dense(128, activation = 'relu')(y)\n",
    "y = keras.layers.Dense(256, activation = 'relu')(y)\n",
    "y = keras.layers.Dense(64, activation = 'relu')(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output=keras.layers.Dense(1,activation='sigmoid',trainable=True)(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "embedding_8 (Embedding)      (None, 64, 50)            2000000   \n",
      "_________________________________________________________________\n",
      "attention_1 (attention)      (None, 50)                114       \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 50, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 20, 96)            1152      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 9, 96)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 9, 256)            123136    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 4, 384)            295296    \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 4, 384)            442752    \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 4, 256)            295168    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 3,240,051\n",
      "Trainable params: 1,240,051\n",
      "Non-trainable params: 2,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=keras.Model(inputs = sequence_input,outputs = output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adadelta(learning_rate=0.0001, rho=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11421 samples, validate on 1270 samples\n",
      "Epoch 1/20\n",
      "11421/11421 [==============================] - 21s 2ms/step - loss: -4825828283071045632.0000 - accuracy: 0.1948 - val_loss: -55385960511479554048.0000 - val_accuracy: 0.2039\n",
      "Epoch 2/20\n",
      "11421/11421 [==============================] - 19s 2ms/step - loss: nan - accuracy: 0.0420 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "11421/11421 [==============================] - 19s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "11421/11421 [==============================] - 19s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      " 8850/11421 [======================>.......] - ETA: 4s - loss: nan - accuracy: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 25\n",
    "\n",
    "history = model.fit(data_train1, Y, epochs=epochs, batch_size=batch_size,validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer(stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Se=cv.fit_transform(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 7155)\t2\n",
      "  (0, 5292)\t4\n",
      "  (0, 22799)\t6\n",
      "  (0, 16109)\t5\n",
      "  (0, 10258)\t5\n",
      "  (0, 24360)\t2\n",
      "  (0, 3360)\t2\n",
      "  (0, 18685)\t2\n",
      "  (0, 10445)\t2\n",
      "  (0, 4218)\t4\n",
      "  (0, 1705)\t2\n",
      "  (0, 9726)\t1\n",
      "  (0, 22441)\t1\n",
      "  (0, 23523)\t1\n",
      "  (0, 20968)\t1\n",
      "  (0, 8031)\t1\n",
      "  (0, 10270)\t2\n",
      "  (0, 10838)\t1\n",
      "  (0, 10401)\t1\n",
      "  (0, 8459)\t1\n",
      "  (0, 24568)\t2\n",
      "  (0, 350)\t1\n",
      "  (0, 5117)\t1\n",
      "  (0, 22598)\t1\n",
      "  (0, 8210)\t1\n",
      "  :\t:\n",
      "  (10053, 19505)\t1\n",
      "  (10053, 21765)\t1\n",
      "  (10053, 13203)\t1\n",
      "  (10053, 14804)\t1\n",
      "  (10053, 1108)\t1\n",
      "  (10053, 6073)\t1\n",
      "  (10053, 25524)\t1\n",
      "  (10053, 23903)\t1\n",
      "  (10053, 25652)\t2\n",
      "  (10053, 5663)\t1\n",
      "  (10053, 17010)\t1\n",
      "  (10053, 10043)\t1\n",
      "  (10053, 8663)\t1\n",
      "  (10053, 17573)\t1\n",
      "  (10053, 16649)\t1\n",
      "  (10053, 13299)\t1\n",
      "  (10053, 17626)\t1\n",
      "  (10053, 24250)\t2\n",
      "  (10053, 1942)\t1\n",
      "  (10053, 18335)\t1\n",
      "  (10053, 23365)\t1\n",
      "  (10053, 5702)\t1\n",
      "  (10053, 14780)\t1\n",
      "  (10053, 12652)\t1\n",
      "  (10053, 13637)\t1\n"
     ]
    }
   ],
   "source": [
    "print(Se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10054, 26831)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Se.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '000a', '000new', '000peopl', '005', '010', '011', '012', '014', '017', '018', '02', '020', '022', '024', '027', '028', '029', '03', '032', '033', '036', '04', '041', '042', '046', '05', '050', '054th', '055', '06', '060', '07', '070', '071', '072', '075', '076', '077', '079', '08', '081', '083', '088', '09', '090', '091', '092', '095', '0em', '0px', '10', '100', '1000', '100px', '100th', '100the', '101', '102', '1021', '103', '1033', '104', '1040', '105', '106', '107', '1070', '108', '108th', '109', '10932', '1096', '109th', '10px', '10th', '11', '110', '11023', '1104', '110th', '111', '111th', '112', '112th', '113', '113th', '114', '115', '116', '117', '119', '11900', '11and', '11s', '11th', '12', '120', '120px']\n"
     ]
    }
   ],
   "source": [
    "print(cv.get_feature_names()[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc=Se.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4 in vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10054, 26831)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc=vc[:,:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train , y_test = train_test_split(data_train1,Y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train , y_test = train_test_split(vc,Y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 3, ..., 0, 1, 5])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10152,) (2539,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   2,   28,   54, ..., 1007,   40, 1679],\n",
       "       [  14,  608,  519, ...,  608,  456, 1521],\n",
       "       [   0,    0,    0, ...,  800, 2472, 1946],\n",
       "       ...,\n",
       "       [  34,  198,   51, ..., 1186,   70,    3],\n",
       "       [   0,    0,    0, ...,   77, 4496,  813],\n",
       "       [   0,    0,    0, ...,  319,   62,   77]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2539, 64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-d61c5b8b2dda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'A' is not defined"
     ]
    }
   ],
   "source": [
    "vc=tfidf.fit_transform(A).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TfidfVectorizer' object has no attribute 'vocabulary_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-45c076d75d2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'TfidfVectorizer' object has no attribute 'vocabulary_'"
     ]
    }
   ],
   "source": [
    "tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=pd.DataFrame(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.to_csv(\"train_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=pd.DataFrame(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.to_csv(\"train_data_labels.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=pd.read_csv(\"train_data_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  4\n",
       "2  3\n",
       "3  0\n",
       "4  3"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.to_csv(\"y_test_labels.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   2,   28,   54, ..., 1007,   40, 1679],\n",
       "       [  14,  608,  519, ...,  608,  456, 1521],\n",
       "       [   0,    0,    0, ...,  800, 2472, 1946],\n",
       "       ...,\n",
       "       [  34,  198,   51, ..., 1186,   70,    3],\n",
       "       [   0,    0,    0, ...,   77, 4496,  813],\n",
       "       [   0,    0,    0, ...,  319,   62,   77]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=pd.DataFrame(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.to_csv(\"data_train_test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10147</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10148</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10149</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10150</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10151</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10152 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0      0\n",
       "1      4\n",
       "2      3\n",
       "3      0\n",
       "4      3\n",
       "...   ..\n",
       "10147  1\n",
       "10148  5\n",
       "10149  0\n",
       "10150  1\n",
       "10151  5\n",
       "\n",
       "[10152 rows x 1 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10152, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2539, 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 2, ..., 2, 3, 0], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2032296179598267"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
